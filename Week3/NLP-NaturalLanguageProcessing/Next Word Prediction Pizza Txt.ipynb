{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "import numpy as np \n",
    "import regex as re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy\n",
    "\n",
    "Corpus = W1 w2 w3 w4. W5 w6 w7 ...... wn\n",
    "\n",
    "\n",
    "X______________________y\n",
    "\n",
    "w1_____________________w2\n",
    "\n",
    "w1 w2__________________w3\n",
    "\n",
    "w1 w2 w3_______________w4\n",
    "\n",
    "w5______________________w6\n",
    "\n",
    "w5 w6_________________w7 and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_sentence_list(file_path): \n",
    "    with open(file_path, 'r') as file: \n",
    "        text = file.read() \n",
    "  \n",
    "    # Splitting the text into sentences using \n",
    "    # delimiters like '.', '?', and '!' \n",
    "    sentences = [sentence.strip() for sentence in re.split( \n",
    "        r'(?<=[.!?])\\s+', text) if sentence.strip()] \n",
    "  \n",
    "    return sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\n",
      "{'the': 1, 'and': 2, 'pizza': 3, 'of': 4, 'a': 5, 'to': 6, 'in': 7, 'has': 8, 'its': 9, 'for': 10, 'with': 11, 'it': 12, 'that': 13, 'is': 14, 'as': 15, 'culinary': 16, 'from': 17, 'become': 18, 'their': 19, 'have': 20, 'on': 21, 'flavors': 22, 'cheese': 23, 'toppings': 24, 'also': 25, 'delivery': 26, 'food': 27, 'people': 28, 'world': 29, 'traditional': 30, 'made': 31, 'experience': 32, 'our': 33, 'pizzerias': 34, 'dish': 35, 'diverse': 36, 'like': 37, 'crust': 38, 'delight': 39, 'symbol': 40, 'pizzas': 41, 'more': 42, 'making': 43, 'or': 44, 'iconic': 45, 'creativity': 46, 'cultural': 47, 'italy': 48, 'an': 49, 'combinations': 50, 'ancient': 51, 'who': 52, 'ingredients': 53, 'we': 54, 'this': 55, 'style': 56, 'home': 57, 'indulgence': 58, 'beyond': 59, 'global': 60, 'inspired': 61, 'options': 62, 'those': 63, 'not': 64, 'but': 65, 'together': 66, 'allowing': 67, 'just': 68, 'comfort': 69, 'local': 70, 'may': 71, 'favorite': 72, 'will': 73, 'taste': 74, 'fusion': 75, 'into': 76, 'all': 77, 'various': 78, 'fresh': 79, 'way': 80, 'by': 81, 'years': 82, 'embraced': 83, 'around': 84, 'rise': 85, 'based': 86, 'mark': 87, 'free': 88, 'dining': 89, 'staple': 90, 'at': 91, 'gatherings': 92, 'joy': 93, 'services': 94, 'technology': 95, 'than': 96, 'popular': 97, 'even': 98, 'bring': 99, 'continues': 100, 'evolve': 101, 'adapt': 102, 'where': 103, 'you': 104, 'can': 105, 'choice': 106, 'process': 107, \"it's\": 108, 'whether': 109, 'dietary': 110, 'future': 111, 'virtual': 112, 'establishments': 113, 'transcended': 114, 'buds': 115, 'testament': 116, 'significance': 117, 'evolved': 118, 'form': 119, 'shared': 120, 'love': 121, 'back': 122, 'centuries': 123, 'civilizations': 124, 'flatbreads': 125, 'vibrant': 126, 'naples': 127, 'today': 128, 'neapolitan': 129, 'topped': 130, 'perfect': 131, 'basil': 132, 'margherita': 133, 'colors': 134, 'italian': 135, 'found': 136, 'united': 137, 'states': 138, 'immigrants': 139, 'late': 140, 'thin': 141, 'over': 142, 'humble': 143, 'chefs': 144, 'cooks': 145, 'thick': 146, 'other': 147, 'variations': 148, 'emerged': 149, 'which': 150, 'exciting': 151, 'sauce': 152, 'spicy': 153, 'while': 154, 'recent': 155, 'plant': 156, 'landscape': 157, 'vegan': 158, 'offering': 159, 'cruelty': 160, 'becoming': 161, 'parties': 162, 'events': 163, 'bringing': 164, 'industry': 165, 'available': 166, 'moreover': 167, 'online': 168, 'platforms': 169, 'ever': 170, 'few': 171, 'realm': 172, 'aspects': 173, 'culture': 174, 'movies': 175, 'earned': 176, 'place': 177, 'hearts': 178, 'journey': 179, 'ability': 180, 'one': 181, 'most': 182, 'beloved': 183, 'innovations': 184, 'phenomenon': 185, 'ensuring': 186, 'lasting': 187, 'memories': 188, 'canvas': 189, 'only': 190, 'aromatic': 191, 'contribute': 192, 'tastes': 193, 'country': 194, 'find': 195, 'called': 196, 'dough': 197, 'catupiry': 198, 'furthermore': 199, 'unique': 200, 'techniques': 201, 'communities': 202, 'many': 203, 'forget': 204, 'go': 205, 'convenience': 206, 'game': 207, 'sense': 208, 'social': 209, 'growing': 210, 'demand': 211, 'preferences': 212, 'gluten': 213, 'popularity': 214, 'enjoy': 215, 'these': 216, 'mobile': 217, 'provide': 218, 'customers': 219, 'undoubtedly': 220, 'technological': 221, 'advancements': 222, 'power': 223, 'innovative': 224, 'impact': 225, 'sports': 226, 'fans': 227, 'make': 228, 'initiatives': 229, 'continue': 230, 'conscious': 231, 'reality': 232, 'delectable': 233, 'borders': 234, 'captivated': 235, 'worldwide': 236, 'extraordinary': 237, 'originating': 238, 'sun': 239, 'kissed': 240, 'lands': 241, 'art': 242, 'unites': 243, 'backgrounds': 244, 'mouthwatering': 245, 'history': 246, 'stretches': 247, 'roots': 248, 'tracing': 249, 'greeks': 250, 'romans': 251, 'egyptians': 252, 'had': 253, 'versions': 254, 'adorned': 255, 'however': 256, 'was': 257, 'city': 258, 'birthed': 259, 'know': 260, 'adore': 261, 'soft': 262, 'chewy': 263, 'balance': 264, 'tomatoes': 265, 'mozzarella': 266, 'pays': 267, 'homage': 268, 'queen': 269, 'embodies': 270, 'flag': 271, 'migrated': 272, 'shores': 273, 'introduced': 274, 'american': 275, 'palate': 276, '19th': 277, 'early': 278, '20th': 279, 'new': 280, 'york': 281, 'characterized': 282, 'foldable': 283, 'generous': 284, 'origins': 285, 'boundless': 286, 'deep': 287, 'chicago': 288, 'buttery': 289, 'layers': 290, 'meanwhile': 291, 'regional': 292, 'such': 293, 'roman': 294, 'known': 295, 'crispy': 296, 'sicilian': 297, 'features': 298, 'fluffy': 299, 'robust': 300, 'forms': 301, 'influences': 302, 'fusions': 303, 'giving': 304, 'multitude': 305, 'styles': 306, 'asian': 307, 'feature': 308, 'teriyaki': 309, 'sriracha': 310, 'kimchi': 311, 'thai': 312, 'mexican': 313, 'boast': 314, 'salsa': 315, 'guacamole': 316, 'chorizo': 317, 'movement': 318, 'tofu': 319, 'creative': 320, 'vegetable': 321, 'delightful': 322, 'seeking': 323, 'sustainable': 324, 'woven': 325, 'itself': 326, 'fabric': 327, 'cultures': 328, 'sporting': 329, 'merely': 330, 'sparking': 331, 'conversation': 332, 'expanded': 333, 'exponentially': 334, 'frozen': 335, 'every': 336, 'corner': 337, 'advent': 338, 'accessible': 339, 'us': 340, 'indulge': 341, 'taps': 342, 'smartphones': 343, 'influence': 344, 'goes': 345, 'permeating': 346, 'delicacies': 347, 'mystic': 348, 'well': 349, 'countless': 350, 'songs': 351, 'artwork': 352, 'fashion': 353, 'trends': 354, 'happiness': 355, 'celebration': 356, 'triangular': 357, 'slices': 358, 'special': 359, 'conclusion': 360, \"pizza's\": 361, 'beginnings': 362, 'fame': 363, 'undeniable': 364, 'charm': 365, 'allure': 366, 'endless': 367, 'possibilities': 368, \"world's\": 369, 'dishes': 370, 'modern': 371, 'day': 372, 'presence': 373, 'plates': 374, 'generations': 375, 'come': 376, 'experimentation': 377, 'alike': 378, 'push': 379, 'boundaries': 380, 'artistry': 381, 'lies': 382, 'presentation': 383, 'vegetables': 384, 'melty': 385, 'cascading': 386, 'edges': 387, 'herbs': 388, 'sprinkled': 389, 'delicately': 390, 'top': 391, 'visual': 392, 'appeal': 393, 'fascinating': 394, 'traveled': 395, 'assimilated': 396, 'traditions': 397, 'each': 398, 'region': 399, 'greece': 400, 'birthplace': 401, 'flatbread': 402, 'variation': 403, 'pita': 404, 'replaced': 405, 'flaky': 406, 'phyllo': 407, 'pastry': 408, 'brazil': 409, 'de': 410, 'frango': 411, 'com': 412, 'featuring': 413, 'shredded': 414, 'chicken': 415, 'creamy': 416, 'india': 417, 'encounter': 418, 'paneer': 419, 'type': 420, 'spices': 421, 'cumin': 422, 'coriander': 423, 'integration': 424, 'acceptance': 425, 'multicultural': 426, 'cities': 427, 'run': 428, 'heritage': 429, 'blending': 430, 'creates': 431, 'beautiful': 432, 'reflects': 433, 'extends': 434, 'consumption': 435, 'cherished': 436, 'tradition': 437, 'households': 438, 'families': 439, 'friends': 440, 'gather': 441, 'kitchen': 442, 'rolling': 443, 'out': 444, 'spreading': 445, 'layering': 446, 'opportunity': 447, 'connection': 448, 'laughter': 449, \"let's\": 450, 'enticing': 451, 'aroma': 452, 'fills': 453, 'air': 454, 'bakes': 455, 'oven': 456, 'teasing': 457, 'senses': 458, 'building': 459, 'anticipation': 460, 'fast': 461, 'quick': 462, 'satisfying': 463, 'meal': 464, 'night': 465, 'craving': 466, 'lunchtime': 467, 'treat': 468, 'ensure': 469, 'piping': 470, 'hot': 471, 'pie': 472, 'phone': 473, 'call': 474, 'away': 475, 'wide': 476, 'availability': 477, 'nights': 478, 'casual': 479, 'brings': 480, 'sparks': 481, 'conversations': 482, 'adds': 483, 'any': 484, 'occasion': 485, 'healthier': 486, 'been': 487, 'swapped': 488, 'alternatives': 489, 'cater': 490, 'restrictions': 491, 'crusts': 492, 'rice': 493, 'flour': 494, 'cauliflower': 495, 'gained': 496, 'intolerance': 497, 'celiac': 498, 'disease': 499, 'meat': 500, 'substitutes': 501, 'onto': 502, 'alternative': 503, 'without': 504, 'compromising': 505, 'becomes': 506, 'interconnected': 507, 'trucks': 508, 'pop': 509, 'up': 510, 'artisanal': 511, 'street': 512, 'corners': 513, 'festivals': 514, 'eateries': 515, 'savor': 516, 'freshly': 517, 'baked': 518, 'immersing': 519, 'themselves': 520, 'bustling': 521, 'atmosphere': 522, 'markets': 523, 'bright': 524, 'see': 525, 'methods': 526, 'automation': 527, 'robotics': 528, 'streamline': 529, 'production': 530, 'consistent': 531, 'quality': 532, 'efficiency': 533, 'kitchens': 534, 'ghost': 535, 'restaurants': 536, 'could': 537, 'expand': 538, 'reach': 539, 'areas': 540, 'previously': 541, 'underserved': 542, 'brick': 543, 'mortar': 544, 'much': 545, 'delicious': 546, 'dishâ€”it': 547, 'captured': 548, 'palates': 549, 'mediterranean': 550, 'sensation': 551, 'showcases': 552, 'adaptability': 553, 'icon': 554, 'exploration': 555, 'enjoyed': 556, 'through': 557, 'satisfy': 558, 'leaving': 559, 'impression': 560, 'fortunate': 561, 'enough': 562, 'magic': 563, 'addition': 564, 'left': 565, 'indelible': 566, 'tv': 567, 'shows': 568, 'literature': 569, 'often': 570, 'depicted': 571, 'quintessential': 572, 'celebrations': 573, 'moments': 574, 'solace': 575, 'scene': 576, 'movie': 577, 'alone': 578, 'kevin': 579, 'mccallister': 580, 'joyfully': 581, 'devours': 582, 'himself': 583, 'synonymous': 584, 'carefree': 585, 'permeated': 586, 'stadiums': 587, 'arenas': 588, 'cheering': 589, 'teams': 590, 'shareable': 591, 'nature': 592, 'days': 593, 'slice': 594, 'grabbed': 595, 'concession': 596, 'stand': 597, 'living': 598, 'room': 599, 'during': 600, 'televised': 601, 'match': 602, 'formed': 603, 'symbiotic': 604, 'relationship': 605, 'enhancing': 606, 'overall': 607, 'economic': 608, 'implications': 609, 'thriving': 610, 'sector': 611, 'generates': 612, 'billions': 613, 'dollars': 614, 'revenue': 615, 'globally': 616, 'ranging': 617, 'small': 618, 'family': 619, 'owned': 620, 'large': 621, 'chains': 622, 'employment': 623, 'opportunities': 624, 'economies': 625, 'created': 626, 'market': 627, 'supports': 628, 'related': 629, 'industries': 630, 'including': 631, 'ingredient': 632, 'suppliers': 633, 'equipment': 634, 'manufacturers': 635, 'medium': 636, 'focused': 637, 'taken': 638, 'philanthropic': 639, 'endeavors': 640, 'using': 641, 'platform': 642, 'support': 643, 'charitable': 644, 'causes': 645, 'positive': 646, 'difference': 647, 'organizing': 648, 'fundraisers': 649, 'donating': 650, 'need': 651, 'showcase': 652, 'force': 653, 'good': 654, 'look': 655, 'changing': 656, 'persist': 657, 'reflect': 658, 'expanding': 659, 'health': 660, 'gain': 661, 'accommodating': 662, 'needs': 663, 'reflecting': 664, 'interest': 665, 'eating': 666, 'play': 667, 'significant': 668, 'role': 669, 'shaping': 670, 'ordering': 671, 'apps': 672, 'drones': 673, 'are': 674, 'examples': 675, 'how': 676, 'revolutionized': 677, 'order': 678, 'augmented': 679, 'enhance': 680, 'explore': 681, 'customize': 682, 'interact': 683, 'digital': 684, 'representations': 685, 'pies': 686}\n"
     ]
    }
   ],
   "source": [
    "file_path = 'pizza.txt'\n",
    "text_data = file_to_sentence_list(file_path)\n",
    "\n",
    "#print (text_data)\n",
    "  \n",
    "# Tokenize the text data to build vocabulary\n",
    "tokenizer = Tokenizer() \n",
    "tokenizer.fit_on_texts(text_data) \n",
    "total_words = len(tokenizer.word_index) + 1  \n",
    "\n",
    "print(total_words)\n",
    "#print(text_data[:5])\n",
    "print(tokenizer.word_index)\n",
    "  \n",
    "# Create input sequences\n",
    "input_sequences = [] \n",
    "for line in text_data: \n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)): \n",
    "        n_gram_sequence = token_list[:i+1] \n",
    "        input_sequences.append(n_gram_sequence)\n",
    "        #print(input_sequences)\n",
    "  \n",
    "# Pad sequences and split into predictors and label \n",
    "max_sequence_len = max([len(seq) for seq in input_sequences]) \n",
    "input_sequences = np.array(pad_sequences( \n",
    "    input_sequences, maxlen=max_sequence_len, padding='pre')) \n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1] \n",
    "\n",
    "# Convert target data to one-hot encoding \n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1628, 39)\n",
      "(1628, 687)\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "\n",
    "#Embedding layer each word is represented in 100 dim dense vector output that is fed into LSTM\n",
    "#each sentence has max_sequence_len-1 (39) input size and each word is represented as a 100 dim vector \n",
    "\n",
    "model.add(Embedding(max_sequence_len-1, 100, trainable = False)) \n",
    "\n",
    "#39 time stamps for each sentence to the network of dimension 150 \n",
    "model.add(LSTM(150)) \n",
    "\n",
    "#output is a softmax layer of vector 687x1 \n",
    "model.add(Dense(total_words, activation='softmax')) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "                optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.0481 - loss: 6.3126\n",
      "Epoch 2/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.0484 - loss: 5.7080\n",
      "Epoch 3/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.0598 - loss: 5.6650\n",
      "Epoch 4/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.0849 - loss: 5.6105\n",
      "Epoch 5/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.0854 - loss: 5.5624\n",
      "Epoch 6/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.0816 - loss: 5.5103\n",
      "Epoch 7/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.1014 - loss: 5.3491\n",
      "Epoch 8/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.0933 - loss: 5.2070\n",
      "Epoch 9/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.1106 - loss: 5.0884\n",
      "Epoch 10/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.1040 - loss: 4.9394\n",
      "Epoch 11/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.1363 - loss: 4.7074\n",
      "Epoch 12/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.1314 - loss: 4.5889\n",
      "Epoch 13/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.1423 - loss: 4.4514\n",
      "Epoch 14/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1465 - loss: 4.2393\n",
      "Epoch 15/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.1524 - loss: 4.1167\n",
      "Epoch 16/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.1804 - loss: 3.9438\n",
      "Epoch 17/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1651 - loss: 3.8794\n",
      "Epoch 18/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.1964 - loss: 3.7060\n",
      "Epoch 19/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.2095 - loss: 3.5795\n",
      "Epoch 20/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.2252 - loss: 3.4558\n",
      "Epoch 21/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.2529 - loss: 3.3122\n",
      "Epoch 22/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.2547 - loss: 3.1806\n",
      "Epoch 23/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.3025 - loss: 3.0579\n",
      "Epoch 24/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.3174 - loss: 2.9750\n",
      "Epoch 25/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.3419 - loss: 2.8628\n",
      "Epoch 26/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.3520 - loss: 2.7761\n",
      "Epoch 27/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 125ms/step - accuracy: 0.3745 - loss: 2.6727\n",
      "Epoch 28/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - accuracy: 0.4110 - loss: 2.5541\n",
      "Epoch 29/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.4356 - loss: 2.4648\n",
      "Epoch 30/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.4844 - loss: 2.3566\n",
      "Epoch 31/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.4992 - loss: 2.2776\n",
      "Epoch 32/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.5244 - loss: 2.1760\n",
      "Epoch 33/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.5440 - loss: 2.0854\n",
      "Epoch 34/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.5746 - loss: 2.0512\n",
      "Epoch 35/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5836 - loss: 1.9394\n",
      "Epoch 36/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.6004 - loss: 1.9051\n",
      "Epoch 37/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.6219 - loss: 1.7921\n",
      "Epoch 38/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.6315 - loss: 1.6998\n",
      "Epoch 39/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.6577 - loss: 1.6319\n",
      "Epoch 40/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - accuracy: 0.6747 - loss: 1.6240\n",
      "Epoch 41/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.7028 - loss: 1.5307\n",
      "Epoch 42/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.7026 - loss: 1.4861\n",
      "Epoch 43/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 139ms/step - accuracy: 0.7196 - loss: 1.4347\n",
      "Epoch 44/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7406 - loss: 1.3936\n",
      "Epoch 45/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - accuracy: 0.7391 - loss: 1.3300\n",
      "Epoch 46/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7595 - loss: 1.2821\n",
      "Epoch 47/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 234ms/step - accuracy: 0.7717 - loss: 1.2467\n",
      "Epoch 48/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - accuracy: 0.7577 - loss: 1.2099\n",
      "Epoch 49/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7954 - loss: 1.1259\n",
      "Epoch 50/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8103 - loss: 1.1133\n",
      "Epoch 51/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8008 - loss: 1.0666\n",
      "Epoch 52/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.7978 - loss: 1.0465\n",
      "Epoch 53/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8122 - loss: 1.0199\n",
      "Epoch 54/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.8151 - loss: 0.9734\n",
      "Epoch 55/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.8498 - loss: 0.9091\n",
      "Epoch 56/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8435 - loss: 0.9059\n",
      "Epoch 57/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8478 - loss: 0.8499\n",
      "Epoch 58/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.8532 - loss: 0.8298\n",
      "Epoch 59/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8560 - loss: 0.8277\n",
      "Epoch 60/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.8741 - loss: 0.7675\n",
      "Epoch 61/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8784 - loss: 0.7490\n",
      "Epoch 62/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8787 - loss: 0.7340\n",
      "Epoch 63/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.8759 - loss: 0.7144\n",
      "Epoch 64/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8780 - loss: 0.7135\n",
      "Epoch 65/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8781 - loss: 0.6908\n",
      "Epoch 66/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.8893 - loss: 0.6404\n",
      "Epoch 67/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8797 - loss: 0.6545\n",
      "Epoch 68/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8917 - loss: 0.6211\n",
      "Epoch 69/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8992 - loss: 0.5826\n",
      "Epoch 70/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8971 - loss: 0.5913\n",
      "Epoch 71/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9084 - loss: 0.5673\n",
      "Epoch 72/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9024 - loss: 0.5444\n",
      "Epoch 73/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9053 - loss: 0.5494\n",
      "Epoch 74/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9048 - loss: 0.5123\n",
      "Epoch 75/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8913 - loss: 0.5437\n",
      "Epoch 76/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8983 - loss: 0.5169\n",
      "Epoch 77/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9117 - loss: 0.4984\n",
      "Epoch 78/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9202 - loss: 0.4452\n",
      "Epoch 79/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9190 - loss: 0.4450\n",
      "Epoch 80/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9175 - loss: 0.4531\n",
      "Epoch 81/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 140ms/step - accuracy: 0.9152 - loss: 0.4473\n",
      "Epoch 82/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9043 - loss: 0.4529\n",
      "Epoch 83/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9185 - loss: 0.4214\n",
      "Epoch 84/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9081 - loss: 0.4279\n",
      "Epoch 85/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9140 - loss: 0.4011\n",
      "Epoch 86/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9076 - loss: 0.4171\n",
      "Epoch 87/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9101 - loss: 0.4037\n",
      "Epoch 88/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9087 - loss: 0.3898\n",
      "Epoch 89/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.9031 - loss: 0.4101\n",
      "Epoch 90/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9083 - loss: 0.3874\n",
      "Epoch 91/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9055 - loss: 0.3948\n",
      "Epoch 92/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9060 - loss: 0.3954\n",
      "Epoch 93/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9175 - loss: 0.3552\n",
      "Epoch 94/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9128 - loss: 0.3319\n",
      "Epoch 95/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9117 - loss: 0.3723\n",
      "Epoch 96/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9133 - loss: 0.3342\n",
      "Epoch 97/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9203 - loss: 0.3336\n",
      "Epoch 98/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9185 - loss: 0.3300\n",
      "Epoch 99/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9154 - loss: 0.3294\n",
      "Epoch 100/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9208 - loss: 0.3219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27c485ec470>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "Next predicted words: Pizza has  become\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Next predicted words: Pizza has  become a\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Next predicted words: Pizza has  become a symbol\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Next predicted words: Pizza has  become a symbol of\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Next predicted words: Pizza has  become a symbol of comfort\n"
     ]
    }
   ],
   "source": [
    "# Generate next word predictions \n",
    "seed_text = \"Pizza has \"\n",
    "next_words = 5\n",
    "  \n",
    "for _ in range(next_words): \n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0] \n",
    "    token_list = pad_sequences( \n",
    "        [token_list], maxlen=max_sequence_len-1, padding='pre') \n",
    "    predicted_probs = model.predict(token_list) \n",
    "    predicted_word = tokenizer.index_word[np.argmax(predicted_probs)] \n",
    "    seed_text += \" \" + predicted_word \n",
    "    print(\"Next predicted words:\", seed_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To improve peformance\n",
    "\n",
    "1. Train with more data\n",
    "2. Hyper parameter tuning - optimizer, epoch, learning rate, input nodes etc.\n",
    "3. Advanced architectures - stacked LSTM, Bi directional LSTM, Transformers (GPT, BERT...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
