{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # to encode text to int\n",
    "from keras.models import Sequential   # the model\n",
    "from keras.utils import pad_sequences # to do padding or truncating\n",
    "\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "from nltk.corpus import stopwords # to get collection of stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    " 'Good work',\n",
    " 'Great effort',\n",
    " 'nice work',\n",
    " 'Excellent!',\n",
    " 'Weak',\n",
    " 'Poor effort!',\n",
    " 'not good',\n",
    " 'poor work',\n",
    " 'Could have done better.']\n",
    "\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "{'unk': 1, 'work': 2, 'done': 3, 'good': 4, 'effort': 5, 'poor': 6, 'well': 7, 'great': 8, 'nice': 9, 'excellent': 10, 'weak': 11, 'not': 12, 'could': 13, 'have': 14, 'better': 15}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('well', 1),\n",
       "             ('done', 2),\n",
       "             ('good', 2),\n",
       "             ('work', 3),\n",
       "             ('great', 1),\n",
       "             ('effort', 2),\n",
       "             ('nice', 1),\n",
       "             ('excellent', 1),\n",
       "             ('weak', 1),\n",
       "             ('poor', 2),\n",
       "             ('not', 1),\n",
       "             ('could', 1),\n",
       "             ('have', 1),\n",
       "             ('better', 1)])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Tokenizer(oov_token='unk')\n",
    "\n",
    "t.fit_on_texts(docs)\n",
    "\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "print(vocab_size)\n",
    "\n",
    "print(t.word_index)\n",
    "\n",
    "t.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 3],\n",
       " [4, 2],\n",
       " [8, 5],\n",
       " [9, 2],\n",
       " [10],\n",
       " [11],\n",
       " [6, 5],\n",
       " [12, 4],\n",
       " [6, 2],\n",
       " [13, 14, 3, 15]]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "\n",
    "encoded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  3,  0,  0],\n",
       "       [ 4,  2,  0,  0],\n",
       "       [ 8,  5,  0,  0],\n",
       "       [ 9,  2,  0,  0],\n",
       "       [10,  0,  0,  0],\n",
       "       [11,  0,  0,  0],\n",
       "       [ 6,  5,  0,  0],\n",
       "       [12,  4,  0,  0],\n",
       "       [ 6,  2,  0,  0],\n",
       "       [13, 14,  3, 15]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=16, output_dim=2))\n",
    "model.add(SimpleRNN(32, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', metrics=['accuracy'], loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2678cca74d0>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs, labels, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "[[0.7803623 ]\n",
      " [0.82317734]\n",
      " [0.78618383]\n",
      " [0.6464689 ]\n",
      " [0.8382696 ]\n",
      " [0.2065256 ]\n",
      " [0.22547609]\n",
      " [0.20346422]\n",
      " [0.22911638]\n",
      " [0.2585748 ]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "[[0.5739226 ]\n",
      " [0.82317734]\n",
      " [0.22911638]\n",
      " [0.6464689 ]\n",
      " [0.8382696 ]\n",
      " [0.2065256 ]\n",
      " [0.22547609]\n",
      " [0.20346422]\n",
      " [0.22911638]\n",
      " [0.2585748 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.predict(padded_docs))\n",
    "\n",
    "padded_docs [0] = [16, 18, 0, 45]\n",
    "padded_docs [2] = [6,  2,  0,  0]\n",
    "\n",
    "print(model.predict(padded_docs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
